{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-On Machine Learning with Scikit-Learn & TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHAPTER 1: The Machine Learning Landscape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Machine Learning => science of programming computers to learn from data  \n",
    "-  Training Set => known examples the computer uses to learn from    \n",
    "-  Accuracy => ratio of correctly classified dependent variable    \n",
    "-  Data Mining => discover previously unknown patterns in data\n",
    "-  Attributes => data type ... aka predictor variable(s) metadata [ex: mileage]\n",
    "-  Features => attribute plus its value ... aka predictor variable(s) [ex: mileage = 15,000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning:\n",
    "-  training data fed to algorithm includes solutions (labels)\n",
    "-  system uses training data to learn from features and labels\n",
    "\n",
    "### Algorithms:\n",
    "-  k-Nearest Neighbors (KNNs)\n",
    "-  Linear Regression\n",
    "-  Logistic Regression\n",
    "-  Support Vector Machines (SVMs)\n",
    "-  Decision Trees and Random Forests\n",
    "-  Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning:\n",
    "-  training data fed to algorithm does not include solutions (unlabeled)\n",
    "-  system tries to learn without a teacher\n",
    "\n",
    "### Algorithms:\n",
    "-  Clustering:\n",
    "    -  k-Means\n",
    "    -  Hierarchical Cluster Analysis (HCA)\n",
    "    -  Expectation Maximization\n",
    "-  Visualization and Dimensionality Reduction\n",
    "    -  Principal Component Analysis (PCA)\n",
    "    -  Kernel PCA\n",
    "    -  Locally-Linear Embedding (LLE)\n",
    "    -  t-distributed Stochastic Neighbor Embedding (t-SNE)\n",
    "-  Association Rule Learning:\n",
    "    -  Apriori\n",
    "    -  Eclat\n",
    "\n",
    "### Examples:\n",
    "-  Dimensionality Reduction:\n",
    "    -  goal is to simplify the data w/o loosing too much information:\n",
    "        -  merge serveral correlated features into one ... aka \"feature extraction\"\n",
    "    -  use DR prior to ML algorithm to improve performance (memory/disk space)\n",
    "-  Anomaly Detection:\n",
    "    -  goal is to detect unusual behaviour in the dataset (outliers)\n",
    "-  Association:\n",
    "    -  goal is to discover interesting relations between attributes (customer buying patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semisupervised Learning:\n",
    "-  training data partially labeled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning:\n",
    "-  Agent:\n",
    "    -  observes environment, select, and perform actions\n",
    "    -  receives \"rewards\" in return or \"penalties\" as negative reward\n",
    "-  Policy:\n",
    "    -  agent must learn by itself to perform best strategy (policy)\n",
    "    -  defines what action the agent should choose when it is in a given situation\n",
    "    \n",
    "### Example:\n",
    "-  Robotic Process Automation\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch [Offline] Learning:\n",
    "-  system is incapable of learning incrementally\n",
    "-  trained offline:\n",
    "    -  1 - system is trained\n",
    "    -  2 - launched into production and runs w/o learning anymore\n",
    "    -  3 - applies results to new data based on what it has learned previously\n",
    "-  incorporating new data to learn from:\n",
    "    -  ***new version must be re-trained on old + new data and then replace old model with new updated model***\n",
    "\n",
    "## Online [Incremental] Learning:\n",
    "-  train the system incrementally by feeding data via mini-batches\n",
    "-  learns about new data on the fly as it arrives\n",
    "-  \"online\" learning typically still done \"offline\"\n",
    "-  solid method for systems with limited computing resources [memory]\n",
    "-  algorithm loads part of the data, runs a training step on the data, and repeats the process until it has trained whole dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance-Based Learning vs. Model-Based Learning Generalizing\n",
    "-  IBL:\n",
    "    -  systems learns from examples by heart via similarity measure:\n",
    "        -  ex: compares word counts between unknown email and known spam email to make a prediction\n",
    "-  MBL:\n",
    "    -  system builds a model via parameter tuning to make predictions\n",
    "    -  uses a performance measure:\n",
    "        -  utility function => measures how good the model is\n",
    "        -  cost function => measures how bad the model is:\n",
    "            -  linear regression ex:  (measures distance between the linear model's prediction and the training examples; **objective is to minimize this distance**\n",
    "            -  algorithm is fed to training data and it finds the parameters that make the linear model fit best to dataset and then can be used to make predictions ... aka **inference**\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Challenges:\n",
    "1.  Bad Algorithm\n",
    "2.  Bad Data (garbage in, garbage out)\n",
    "    -  missing / null values\n",
    "    -  small / flawed samples (training set) => sampling noise / sampling bias\n",
    "    -  outliers / errors\n",
    "    -  irrelevant features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Feature Engineering:\n",
    "-  Feature Selection => selects most useful features for training\n",
    "-  Feature Extraction => combines existing features into more useful one (ex: dimensionality reduction algorithms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting [a too complex model]:\n",
    "-  model performs well on training data, but does not generalize (bias) well when applying model\n",
    "-  \"overfitting\" occurs when the model is too complex relative to the amount / noiseness of the training data\n",
    "-  solutions:\n",
    "    -  include fewer attributes in training data\n",
    "    -  constraining the model ... aka regularization [how well the model is fit to the training data]:\n",
    "        -  large regularization parameter will avoid overfitting but produce a small slope and have trouble building a good model\n",
    "    -  gather more training data\n",
    "    -  reduce noise (clean data / remove outliers) in training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Underfitting [a too simple model]:\n",
    "-  model is too simple to learn from the underlying structure of the data\n",
    "-  solutions:\n",
    "    -  select more powerful model with more parameters\n",
    "    -  feeding better features to the learning algorithm (feature engineering)\n",
    "    -  reduce constraints on model (reduce regularization hyperparameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter:\n",
    "-  parameter of a learning algorithm set prior to training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing / Validating:\n",
    "-  split data into training (usually 80%) and test (usually 20%) sets\n",
    "-  generalization error => error rate via test set (data model has never seen)\n",
    "-  ex: training error is low / generalization error is high => model is overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation:\n",
    "-  training set is split into complementary subsets\n",
    "-  each model is trained against a different combination of these subsets and validated against the remaining part\n",
    "-  Process:\n",
    "    1.  train multiple models with various hyperparameters using training set\n",
    "    2.  select best model / hyperparameters that performs on validation set\n",
    "    3.  run best model on test set to get an estimate of the generalization error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Exercises_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.linear_model\n",
    "import sklearn.neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d1 = '/Users/grp/handsOnMLwSL&TF/datasets/lifesat/oecd_bli_2015.csv'\n",
    "d2 = '/Users/grp/handsOnMLwSL&TF/datasets/lifesat/gdp_per_capita.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_country_stats(oecd_bli, gdp_per_capita):\n",
    "    \n",
    "    \"\"\"merges the OECD's life satisfaction data and the IMF's GDP per capita data\"\"\"\n",
    "    \n",
    "    oecd_bli = oecd_bli[oecd_bli[\"INEQUALITY\"]==\"TOT\"]\n",
    "    oecd_bli = oecd_bli.pivot(index=\"Country\", columns=\"Indicator\", values=\"Value\")\n",
    "    gdp_per_capita.rename(columns={\"2015\": \"GDP per capita\"}, inplace=True)\n",
    "    gdp_per_capita.set_index(\"Country\", inplace=True)\n",
    "    full_country_stats = pd.merge(left=oecd_bli, right=gdp_per_capita, left_index=True, right_index=True)\n",
    "    full_country_stats.sort_values(by=\"GDP per capita\", inplace=True)\n",
    "    remove_indices = [0, 1, 6, 8, 33, 34, 35]\n",
    "    keep_indices = list(set(range(36)) - set(remove_indices))\n",
    "    return full_country_stats[[\"GDP per capita\", 'Life satisfaction']].iloc[keep_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10457e550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.96242338]]\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "oecd_bli = pd.read_csv(d1, thousands=',')\n",
    "gdp_per_capita = pd.read_csv(d2, thousands=',',delimiter='\\t', encoding='latin1', na_values=\"n/a\")\n",
    "\n",
    "# Prepare the data\n",
    "country_stats = prepare_country_stats(oecd_bli, gdp_per_capita)\n",
    "X = np.c_[country_stats[\"GDP per capita\"]]\n",
    "y = np.c_[country_stats[\"Life satisfaction\"]]\n",
    "\n",
    "# Visualize the data\n",
    "country_stats.plot(kind='scatter', x=\"GDP per capita\", y='Life satisfaction')\n",
    "plt.show()\n",
    "\n",
    "# Select a linear model\n",
    "lr = sklearn.linear_model.LinearRegression()\n",
    "model = lr\n",
    "\n",
    "# Select a neighbor model\n",
    "# model = sklearn.neighbors.KNeighborsRegressor(n_neighbors=3)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make a prediction for Cyprus\n",
    "X_new = [[22587]]  # Cyprus' GDP per capita\n",
    "print(model.predict(X_new)) # outputs [[ 5.96242338]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. How would you define Machine Learning?**\n",
    "\n",
    "_Machine Learning is about building systems that can learn from data. Learning means getting better at some task, given some performance measure._\n",
    "\n",
    "**2. Can you name four types of problems where it shines?**\n",
    "\n",
    "_Machine Learning is great for complex problems for which we have no algorithmic solution, to replace long lists of hand-tuned rules, to build systems that adapt to fluctuating environments, and finally to help humans learn (e.g., data mining)._\n",
    "\n",
    "**3. What is a labeled training set?**\n",
    "\n",
    "_A labeled training set is a training set that contains the desired solution (a.k.a. a label) for each instance._\n",
    "\n",
    "**4. What are the two most common supervised tasks?**\n",
    "\n",
    "_The two most common supervised tasks are regression and classification._\n",
    "\n",
    "**5. Can you name four common unsupervised tasks?**\n",
    "\n",
    "_Common unsupervised tasks include clustering, visualization, dimensionality reduction, and association rule learning._\n",
    "\n",
    "**6. What type of Machine Learning algorithm would you use to allow a robot to walk in various unknown terrains?**\n",
    "\n",
    "_Reinforcement Learning is likely to perform best if we want a robot to learn to walk in various unknown terrains since this is typically the type of problem that Reinforcement Learning tackles. It might be possible to express the problem as a supervised or semisupervised learning problem, but it would be less natural._\n",
    "\n",
    "**7. What type of algorithm would you use to segment your customers into multiple groups?**\n",
    "\n",
    "_If you don’t know how to define the groups, then you can use a clustering algorithm (unsupervised learning) to segment your customers into clusters of similar customers. However, if you know what groups you would like to have, then you can feed many examples of each group to a classification algorithm (supervised learning), and it will classify all your customers into these groups._\n",
    "\n",
    "**8. Would you frame the problem of spam detection as a supervised learning problem or an unsupervised learning problem?**\n",
    "\n",
    "_Spam detection is a typical supervised learning problem: the algorithm is fed many emails along with their label (spam or not spam)._\n",
    "\n",
    "**9. What is an online learning system?**\n",
    "\n",
    "_An online learning system can learn incrementally, as opposed to a batch learning system. This makes it capable of adapting rapidly to both changing data and autonomous systems, and of training on very large quantities of data._\n",
    "\n",
    "**10. What is out-of-core learning?**\n",
    "\n",
    "_Out-of-core algorithms can handle vast quantities of data that cannot fit in a computer’s main memory. An out-of-core learning algorithm chops the data into mini-batches and uses online learning techniques to learn from these mini-batches._\n",
    "\n",
    "**11. What type of learning algorithm relies on a similarity measure to make predictions?**\n",
    "\n",
    "_An instance-based learning system learns the training data by heart; then, when given a new instance, it uses a similarity measure to find the most similar learned instances and uses them to make predictions._\n",
    "\n",
    "**12. What is the difference between a model parameter and a learning algorithm’s hyperparameter?**\n",
    "\n",
    "_A model has one or more model parameters that determine what it will predict given a new instance (e.g., the slope of a linear model). A learning algorithm tries to find optimal values for these parameters such that the model generalizes well to new instances. A hyperparameter is a parameter of the learning algorithm itself, not of the model (e.g., the amount of regularization to apply)._\n",
    "\n",
    "**13. What do model-based learning algorithms search for? What is the most common strategy they use to succeed? How do they make predictions?**\n",
    "\n",
    "_Model-based learning algorithms search for an optimal value for the model parameters such that the model will generalize well to new instances. We usually train such systems by minimizing a cost function that measures how bad the system is at making predictions on the training data, plus a penalty for model complexity if the model is regularized. To make predictions, we feed the new instance’s features into the model’s prediction function, using the parameter values found by the learning algorithm._\n",
    "\n",
    "**14. Can you name four of the main challenges in Machine Learning?**\n",
    "\n",
    "_Some of the main challenges in Machine Learning are the lack of data, poor data quality, nonrepresentative data, uninformative features, excessively simple models that underfit the training data, and excessively complex models that overfit the data._\n",
    "\n",
    "**15. If your model performs great on the training data but generalizes poorly to new instances, what is happening? Can you name three possible solutions?**\n",
    "\n",
    "_If a model performs great on the training data but generalizes poorly to new instances, the model is likely overfitting the training data (or we got extremely lucky on the training data). Possible solutions to overfitting are getting more data, simplifying the model (selecting a simpler algorithm, reducing the number of parameters or features used, or regularizing the model), or reducing the noise in the training data._\n",
    "\n",
    "**16. What is a test set and why would you want to use it?**\n",
    "\n",
    "_A test set is used to estimate the generalization error that a model will make on new instances, before the model is launched in production._\n",
    "\n",
    "**17. What is the purpose of a validation set?**\n",
    "\n",
    "_A validation set is used to compare models. It makes it possible to select the best model and tune the hyperparameters._\n",
    "\n",
    "**18. What can go wrong if you tune hyperparameters using the test set?**\n",
    "\n",
    "_If you tune hyperparameters using the test set, you risk overfitting the test set, and the generalization error you measure will be optimistic (you may launch a model that performs worse than you expect)._\n",
    "\n",
    "**19. What is cross-validation and why would you prefer it to a validation set?**\n",
    "\n",
    "_Cross-validation is a technique that makes it possible to compare models (for model selection and hyperparameter tuning) without the need for a separate validation set. This saves precious training data._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
